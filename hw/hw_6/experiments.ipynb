{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "644072dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Subset, Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from torchvision.models import mobilenet_v2, MobileNet_V2_Weights\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class BirdsDataset(Dataset):\n",
    "    def __init__(self, gt, img_dir, *, train=True, transform):\n",
    "        self._items = []\n",
    "\n",
    "        train_gt, val_gt = train_test_split(list(gt.items()), test_size=0.3, shuffle=True, random_state=0)\n",
    "        gt = train_gt if train else val_gt\n",
    "\n",
    "        for img_filename, class_id in gt:\n",
    "            img_path = os.path.join(train_img_dir, img_filename)\n",
    "            self._items.append((img_path, class_id))\n",
    "\n",
    "        self._transform = transform\n",
    "\n",
    "        self.classes = np.sort(np.unique([class_id for _, class_id in gt]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._items)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path, class_id = self._items[index]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self._transform:\n",
    "            img = self._transform(img)\n",
    "\n",
    "        return img, class_id\n",
    "\n",
    "\n",
    "class MobileNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = mobilenet_v2(weights=MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "        self.model.classifier[1] = torch.nn.Linear(1280, num_classes)\n",
    "\n",
    "        for child in list(self.model.children())[:-4]:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.model(x), dim=1)\n",
    "\n",
    "\n",
    "def train_epoch(model, optimizer, criterion, train_loader, device, tqdm_desc):\n",
    "    model.train()\n",
    "    train_acc, train_loss = 0.0, 0.0\n",
    "\n",
    "    for images, class_ids in tqdm(train_loader, desc=tqdm_desc):\n",
    "        images = images.to(device)\n",
    "        class_ids = class_ids.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, class_ids)\n",
    "\n",
    "        criterion.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_acc += (logits.argmax(dim=1) == class_ids).sum().item()\n",
    "        train_loss += loss.item() * class_ids.shape[0]\n",
    "\n",
    "    train_acc /= len(train_loader.dataset)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    return train_acc, train_loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def val_epoch(model, criterion, val_loader, device, tqdm_desc):\n",
    "    model.train()\n",
    "    val_acc, val_loss = 0.0, 0.0\n",
    "\n",
    "    for images, class_ids in tqdm(val_loader, desc=tqdm_desc):\n",
    "        images = images.to(device)\n",
    "        class_ids = class_ids.to(device)\n",
    "\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, class_ids)\n",
    "\n",
    "        val_acc += (logits.argmax(dim=1) == class_ids).sum().item()\n",
    "        val_loss += loss.item() * class_ids.shape[0]\n",
    "\n",
    "    val_acc /= len(val_loader.dataset)\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    return val_acc, val_loss\n",
    "\n",
    "\n",
    "def train(model, optimizer, criterion, scheduler, train_loader, val_loader, device, num_epochs):\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_acc, train_loss = train_epoch(model, optimizer, criterion, train_loader, device, f'training {epoch}/{num_epochs}')\n",
    "        val_acc, val_loss = val_epoch(model, criterion, val_loader, device, f'training {epoch}/{num_epochs}')\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        print(f\"train_acc {train_acc} train_loss {train_loss}\")\n",
    "        print(f\"val_acc {val_acc} val_loss {val_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32f8fbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "def read_csv(filename):\n",
    "    res = {}\n",
    "    with open(filename) as fhandle:\n",
    "        next(fhandle)\n",
    "        for line in fhandle:\n",
    "            filename, class_id = line.rstrip('\\n').split(',')\n",
    "            res[filename] = int(class_id)\n",
    "    return res\n",
    "\n",
    "data_dir = \"tests/00_test_img_input\"\n",
    "train_dir = join(data_dir, 'train')\n",
    "train_gt = read_csv(join(train_dir, 'gt.csv'))\n",
    "train_img_dir = join(train_dir, 'images')\n",
    "\n",
    "batch_size = 32\n",
    "num_epochs = 3\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.RandomResizedCrop(224, scale=(0.5, 1.0)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "val_transform = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "train_dataset = BirdsDataset(train_gt, train_img_dir, train=True, transform=train_transform)\n",
    "val_dataset = BirdsDataset(train_gt, train_img_dir, train=False, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = MobileNet(len(train_dataset.classes)).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-2)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = None #torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e52bbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, class_ids = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7657a7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5    \n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0c3972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a79f0898a544f899b5f9960b84c8dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training 1/3:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(model, optimizer, criterion, scheduler, train_loader, val_loader, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10074515",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
